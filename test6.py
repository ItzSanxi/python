import os
import glob
import itertools
from PIL import Image
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader


# ==========================
# 1. å®šä¹‰ DnCNN æ¨¡å‹
# ==========================
class DnCNN(nn.Module):
    def __init__(self, channels=1, num_layers=17, features=64):
        super(DnCNN, self).__init__()
        layers = []
        layers.append(nn.Conv2d(channels, features, kernel_size=3, padding=1))
        layers.append(nn.ReLU(inplace=True))
        for _ in range(num_layers - 2):
            layers.append(nn.Conv2d(features, features, kernel_size=3, padding=1, bias=False))
            layers.append(nn.BatchNorm2d(features))
            layers.append(nn.ReLU(inplace=True))
        layers.append(nn.Conv2d(features, channels, kernel_size=3, padding=1, bias=False))
        self.dncnn = nn.Sequential(*layers)

    def forward(self, x):
        noise = self.dncnn(x)
        return x - noise  # è¾“å‡ºå»å™ªå›¾åƒ


# ==========================
# 2. BSD300 æ•°æ®é›†ç±»ï¼ˆè‡ªåŠ¨è°ƒæ•´ä¸º128x128ï¼‰
# ==========================
class BSD300Dataset(Dataset):
    def __init__(self, image_dir, ground_dir, grayscale=True, target_size=(128, 128)):
        self.grayscale = grayscale
        self.target_size = target_size

        # æ£€æŸ¥è·¯å¾„
        if not os.path.exists(image_dir):
            raise FileNotFoundError(f"âŒ è®­ç»ƒå›¾åƒè·¯å¾„ä¸å­˜åœ¨: {image_dir}")
        if not os.path.exists(ground_dir):
            raise FileNotFoundError(f"âŒ Ground Truth è·¯å¾„ä¸å­˜åœ¨: {ground_dir}")

        # æ”¯æŒå¤šç§æ ¼å¼
        exts = ('*.png', '*.jpg', '*.jpeg', '*.bmp')
        self.image_files = sorted(itertools.chain.from_iterable(
            glob.glob(os.path.join(image_dir, ext)) for ext in exts))
        self.ground_files = sorted(itertools.chain.from_iterable(
            glob.glob(os.path.join(ground_dir, ext)) for ext in exts))

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶
        if len(self.image_files) == 0:
            raise RuntimeError(f"âš ï¸ æœªåœ¨ {image_dir} ä¸­æ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„æˆ–æ‰©å±•å")
        if len(self.ground_files) == 0:
            raise RuntimeError(f"âš ï¸ æœªåœ¨ {ground_dir} ä¸­æ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„æˆ–æ‰©å±•å")

        # æ£€æŸ¥æ•°é‡æ˜¯å¦åŒ¹é…
        if len(self.image_files) != len(self.ground_files):
            raise ValueError(f"âš ï¸ train_image ä¸ train_ground æ•°é‡ä¸åŒ¹é…ï¼š{len(self.image_files)} vs {len(self.ground_files)}")

        print(f"âœ… åŠ è½½æ•°æ®é›†æˆåŠŸ: {len(self.image_files)} å¼ å›¾åƒ")
        print(f"   æ¥è‡ª: {image_dir}")
        print(f"   Ground Truth: {ground_dir}")
        print(f"   æ‰€æœ‰å›¾åƒå°†è¢«è°ƒæ•´ä¸º: {target_size}")

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_noisy = Image.open(self.image_files[idx])
        img_clean = Image.open(self.ground_files[idx])

        # è½¬ç°åº¦æˆ–RGB
        if self.grayscale:
            img_noisy = img_noisy.convert('L')
            img_clean = img_clean.convert('L')
        else:
            img_noisy = img_noisy.convert('RGB')
            img_clean = img_clean.convert('RGB')

        # âœ… ç»Ÿä¸€åˆ° 128x128 å°ºå¯¸
        img_noisy = img_noisy.resize(self.target_size, Image.BICUBIC)
        img_clean = img_clean.resize(self.target_size, Image.BICUBIC)

        # è½¬ä¸ºå¼ é‡ï¼ˆ0~1ï¼‰
        noisy = np.array(img_noisy).astype(np.float32) / 255.0
        clean = np.array(img_clean).astype(np.float32) / 255.0

        if self.grayscale:
            noisy = np.expand_dims(noisy, axis=0)
            clean = np.expand_dims(clean, axis=0)
        else:
            noisy = noisy.transpose((2, 0, 1))
            clean = clean.transpose((2, 0, 1))

        return torch.from_numpy(noisy), torch.from_numpy(clean)


# ==========================
# 3. è®­ç»ƒæµç¨‹
# ==========================
def train_dncnn(train_image_dir, train_ground_dir, save_dir='./checkpoints',
                epochs=30, batch_size=8, lr=1e-3, grayscale=True):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½æ•°æ®
    train_dataset = BSD300Dataset(train_image_dir, train_ground_dir, grayscale=grayscale, target_size=(128, 128))
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)

    # å®šä¹‰æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    channels = 1 if grayscale else 3
    model = DnCNN(channels=channels).to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)

    os.makedirs(save_dir, exist_ok=True)

    print("\nå¼€å§‹è®­ç»ƒ DnCNN æ¨¡å‹...\n")
    for epoch in range(1, epochs + 1):
        model.train()
        running_loss = 0.0
        for noisy, clean in train_loader:
            noisy, clean = noisy.to(device), clean.to(device)
            output = model(noisy)
            loss = criterion(output, clean)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        avg_loss = running_loss / len(train_loader)
        print(f"Epoch [{epoch}/{epochs}] - å¹³å‡Loss: {avg_loss:.6f}")

        # ä¿å­˜æ¨¡å‹
        model_path = os.path.join(save_dir, f'dncnn_128_epoch_{epoch}.pth')
        torch.save(model.state_dict(), model_path)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")

    print("\nğŸ‰ è®­ç»ƒç»“æŸï¼æ¨¡å‹å·²å…¨éƒ¨ä¿å­˜ã€‚")


# ==========================
# 4. ä¸»ç¨‹åºå…¥å£
# ==========================
if __name__ == '__main__':
    train_dncnn(
        train_image_dir=r'E:\Projects\python\BSD300\train_image',   # ä¿®æ”¹ä¸ºä½ çš„è·¯å¾„
        train_ground_dir=r'E:\Projects\python\BSD300\train_ground', # ä¿®æ”¹ä¸ºä½ çš„è·¯å¾„
        save_dir=r'E:\Projects\python\checkpoints',
        epochs=10,           # å¯è°ƒ
        batch_size=4,        # å¯è°ƒ
        lr=1e-3,
        grayscale=True        # è‹¥è¦è®­ç»ƒå½©è‰²å›¾ç‰‡ï¼Œæ”¹æˆ False
    )
